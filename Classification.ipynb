{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61710b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/salemi/Documents/Kaggle/happywhale\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py as h5\n",
    "import mlflow\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Custom library in dev\n",
    "import happy as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf08288",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "698dea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter dictionnary\n",
    "P = {}\n",
    "\n",
    "P[\"TEST_RUN\"] = True\n",
    "\n",
    "P[\"TRAIN_CSV\"] = \"input/happy-whale-and-dolphin/train.csv\"\n",
    "\n",
    "P[\"TRAIN_FOLDER\"] = \"input/happy-whale-and-dolphin/train_images\"\n",
    "\n",
    "P[\"BATCH_SIZE\"] = 32\n",
    "\n",
    "P[\"EPOCHS\"] = 10\n",
    "\n",
    "P[\"LEARNING_RATE\"] = 1e-3\n",
    "\n",
    "P[\"LEARNING_RATE_FINETUNING\"] = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aac494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(P[\"TRAIN_CSV\"])\n",
    "\n",
    "if P[\"TEST_RUN\"]:\n",
    "    data_df = data_df.iloc[:1500]\n",
    "\n",
    "species, counts = np.unique(data_df[\"species\"], return_counts=True)\n",
    "\n",
    "P[\"CUTOFF\"] = int(np.floor(np.max(counts) * 0.07))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce17879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS NAME                    COUNTS    PERCENTAGE\n",
      "--------------------------------------------------\n",
      "bottlenose_dolphin            284       18.93     \n",
      "beluga                        227       15.13     \n",
      "humpback_whale                207       13.80     \n",
      "blue_whale                    135       9.00      \n",
      "false_killer_whale            103       6.87      \n",
      "dusky_dolphin                 86        5.73      \n",
      "minke_whale                   51        3.40      \n",
      "melon_headed_whale            50        3.33      \n",
      "spinner_dolphin               47        3.13      \n",
      "killer_whale                  44        2.93      \n",
      "gray_whale                    34        2.27      \n",
      "fin_whale                     33        2.20      \n",
      "southern_right_whale          30        2.00      \n",
      "bottlenose_dolpin             29        1.93      \n",
      "kiler_whale                   28        1.87      \n",
      "spotted_dolphin               21        1.40      \n",
      "short_finned_pilot_whale      16        1.07      \n",
      "sei_whale                     13        0.87      \n",
      "cuviers_beaked_whale          11        0.73      \n",
      "common_dolphin                11        0.73      \n",
      "pilot_whale                   9         0.60      \n",
      "long_finned_pilot_whale       6         0.40      \n",
      "brydes_whale                  6         0.40      \n",
      "commersons_dolphin            5         0.33      \n",
      "white_sided_dolphin           5         0.33      \n",
      "globis                        3         0.20      \n",
      "pantropic_spotted_dolphin     3         0.20      \n",
      "rough_toothed_dolphin         3         0.20      \n"
     ]
    }
   ],
   "source": [
    "hp.print_class_statistics(data_df, \"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67326ce5",
   "metadata": {},
   "source": [
    "The classes in this dataset, the column \"species\", are too imbalanced. Let's group some less represented classes to get something significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f560f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>species</th>\n",
       "      <th>individual_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00021adfb725ed.jpg</td>\n",
       "      <td>melon_headed_whale</td>\n",
       "      <td>cadddb1636b9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000562241d384d.jpg</td>\n",
       "      <td>humpback_whale</td>\n",
       "      <td>1a71fbb72250</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0007c33415ce37.jpg</td>\n",
       "      <td>false_killer_whale</td>\n",
       "      <td>60008f293a2b</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0007d9bca26a99.jpg</td>\n",
       "      <td>bottlenose_dolphin</td>\n",
       "      <td>4b00fe572063</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00087baf5cef7a.jpg</td>\n",
       "      <td>humpback_whale</td>\n",
       "      <td>8e5253662392</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                image             species individual_id  class\n",
       "0  00021adfb725ed.jpg  melon_headed_whale  cadddb1636b9     12\n",
       "1  000562241d384d.jpg      humpback_whale  1a71fbb72250     17\n",
       "2  0007c33415ce37.jpg  false_killer_whale  60008f293a2b     15\n",
       "3  0007d9bca26a99.jpg  bottlenose_dolphin  4b00fe572063     19\n",
       "4  00087baf5cef7a.jpg      humpback_whale  8e5253662392     17"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classes are too much imbalanced, let's group the one with few example\n",
    "unique_species, count_species = np.unique(data_df[\"species\"], return_counts=True)\n",
    "\n",
    "unique_species = unique_species[np.argsort(count_species)]\n",
    "count_species = count_species[np.argsort(count_species)]\n",
    "\n",
    "map_species = {}\n",
    "idx = 0 \n",
    "acc = 0\n",
    "name = []\n",
    "for i, j in zip(count_species, unique_species):\n",
    "    acc += i\n",
    "    name.append(j)    \n",
    "    if acc >= P[\"CUTOFF\"]:\n",
    "        for n in name:\n",
    "            map_species[n] = idx\n",
    "        idx += 1\n",
    "        acc = 0\n",
    "        name = []\n",
    "            \n",
    "        \n",
    "    \n",
    "data_df[\"class\"] = data_df.apply(lambda x: map_species[x[\"species\"]], axis=1)\n",
    "        \n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df8a5b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS NAME                    COUNTS    PERCENTAGE\n",
      "--------------------------------------------------\n",
      "19                            284       18.93     \n",
      "18                            227       15.13     \n",
      "17                            207       13.80     \n",
      "16                            135       9.00      \n",
      "15                            103       6.87      \n",
      "14                            86        5.73      \n",
      "13                            51        3.40      \n",
      "12                            50        3.33      \n",
      "11                            47        3.13      \n",
      "10                            44        2.93      \n",
      "9                             34        2.27      \n",
      "8                             33        2.20      \n",
      "7                             30        2.00      \n",
      "6                             29        1.93      \n",
      "3                             29        1.93      \n",
      "5                             28        1.87      \n",
      "2                             22        1.47      \n",
      "4                             21        1.40      \n",
      "1                             21        1.40      \n",
      "0                             19        1.27      \n"
     ]
    }
   ],
   "source": [
    "hp.print_class_statistics(data_df, \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3453e82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for train set:\n",
      "CLASS NAME                    COUNTS    PERCENTAGE\n",
      "--------------------------------------------------\n",
      "19                            227       18.92     \n",
      "18                            181       15.08     \n",
      "17                            165       13.75     \n",
      "16                            108       9.00      \n",
      "15                            83        6.92      \n",
      "14                            68        5.67      \n",
      "13                            41        3.42      \n",
      "12                            40        3.33      \n",
      "11                            37        3.08      \n",
      "10                            36        3.00      \n",
      "8                             27        2.25      \n",
      "9                             27        2.25      \n",
      "7                             24        2.00      \n",
      "6                             24        2.00      \n",
      "5                             23        1.92      \n",
      "3                             23        1.92      \n",
      "2                             17        1.42      \n",
      "1                             17        1.42      \n",
      "4                             16        1.33      \n",
      "0                             16        1.33      \n",
      "\n",
      "Stats for val set:\n",
      "CLASS NAME                    COUNTS    PERCENTAGE\n",
      "--------------------------------------------------\n",
      "19                            57        19.00     \n",
      "18                            46        15.33     \n",
      "17                            42        14.00     \n",
      "16                            27        9.00      \n",
      "15                            20        6.67      \n",
      "14                            18        6.00      \n",
      "13                            10        3.33      \n",
      "12                            10        3.33      \n",
      "11                            10        3.33      \n",
      "10                            8         2.67      \n",
      "9                             7         2.33      \n",
      "8                             6         2.00      \n",
      "7                             6         2.00      \n",
      "3                             6         2.00      \n",
      "6                             5         1.67      \n",
      "5                             5         1.67      \n",
      "4                             5         1.67      \n",
      "2                             5         1.67      \n",
      "1                             4         1.33      \n",
      "0                             3         1.00      \n"
     ]
    }
   ],
   "source": [
    "# 80 / 20 split\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "train_index, val_index = next(skf.split(np.zeros(len(data_df)), data_df[\"class\"].values))\n",
    "\n",
    "train_df = data_df.loc[train_index].copy()\n",
    "val_df = data_df.loc[val_index].copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Stats for train set:\")\n",
    "hp.print_class_statistics(train_df, \"class\")\n",
    "\n",
    "print(\"\\nStats for val set:\")\n",
    "hp.print_class_statistics(val_df, \"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4a0fd5",
   "metadata": {},
   "source": [
    "The splits looks fairly good with a conserved class prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "616557b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 76 122 171]\n",
      "  [ 76 124 170]\n",
      "  [ 84 127 174]\n",
      "  ...\n",
      "  [ 62 100 147]\n",
      "  [ 63  99 151]\n",
      "  [ 60 101 150]]\n",
      "\n",
      " [[ 89 136 178]\n",
      "  [ 86 134 174]\n",
      "  [ 94 139 179]\n",
      "  ...\n",
      "  [ 49  86 131]\n",
      "  [ 53  87 136]\n",
      "  [ 56  90 138]]\n",
      "\n",
      " [[ 87 132 174]\n",
      "  [ 92 137 178]\n",
      "  [ 90 136 177]\n",
      "  ...\n",
      "  [ 58  92 137]\n",
      "  [ 59  93 138]\n",
      "  [ 60  92 139]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 47  44  53]\n",
      "  [ 47  46  54]\n",
      "  [ 44  44  52]\n",
      "  ...\n",
      "  [ 48  47  55]\n",
      "  [ 47  47  55]\n",
      "  [ 49  46  55]]\n",
      "\n",
      " [[ 43  43  51]\n",
      "  [ 42  42  50]\n",
      "  [ 47  46  54]\n",
      "  ...\n",
      "  [ 49  48  56]\n",
      "  [ 48  48  56]\n",
      "  [ 48  47  55]]\n",
      "\n",
      " [[ 40  43  52]\n",
      "  [ 43  43  53]\n",
      "  [ 43  41  52]\n",
      "  ...\n",
      "  [ 51  50  59]\n",
      "  [ 52  51  59]\n",
      "  [ 49  49  57]]], shape=(224, 224, 3), dtype=uint8) tf.Tensor(12, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "class ShardedGenerator:\n",
    "    def __init__(self, df: pd.DataFrame, n_shards: int = None):\n",
    "        \n",
    "        self._df = df.copy()\n",
    "                \n",
    "        self._n_shards = n_shards\n",
    "        if self._n_shards is None:\n",
    "            self._n_shards = cpu_count()\n",
    "            \n",
    "        self._df[\"filepath\"] = self._df.apply(lambda x: os.path.join(P[\"TRAIN_FOLDER\"], x[\"image\"]), axis=1)\n",
    "        \n",
    "        \n",
    "    def __call__(self, n):\n",
    "        with h5.File(\"preprocessed_224-224/data.h5\", \"r\") as f:\n",
    "            for count, (i, row) in enumerate(self._df.iterrows()):\n",
    "                if count % self._n_shards != n:\n",
    "                    continue\n",
    "                    \n",
    "                img = tf.convert_to_tensor(f[\"img\"][i])\n",
    "                \n",
    "                label = tf.convert_to_tensor(row[\"class\"], dtype=tf.int64)\n",
    "\n",
    "                yield img, label\n",
    "                \n",
    "                \n",
    "gen = ShardedGenerator(train_df, 1)\n",
    "\n",
    "for i, j in gen(0):\n",
    "    print(i, j)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afc9b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(data:pd.DataFrame, n_shards=4):\n",
    "    gen = ShardedGenerator(data, n_shards)\n",
    "\n",
    "    out_sign = (tf.TensorSpec(shape=(224, 224, 3), dtype=tf.uint8), tf.TensorSpec(shape=(), dtype=tf.int64))\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices(np.arange(n_shards))\n",
    "\n",
    "    ds = ds.interleave(lambda x: tf.data.Dataset.from_generator(gen, output_signature=out_sign, args=(x,)),\n",
    "                       cycle_length=n_shards,\n",
    "                       block_length=1,\n",
    "                       num_parallel_calls=n_shards,\n",
    "                       deterministic=True)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "\n",
    "P[\"STEPS_PER_EPOCH\"] = int(np.ceil(len(train_df) / P[\"BATCH_SIZE\"]))\n",
    "\n",
    "\n",
    "ds_train = get_dataset(train_df, n_shards=16)\n",
    "ds_train = ds_train.batch(P[\"BATCH_SIZE\"]).cache()\n",
    "ds_train = ds_train.map(lambda x, y: (tf.image.convert_image_dtype(x, tf.float32), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE).repeat(P[\"EPOCHS\"])\n",
    "\n",
    "\n",
    "ds_val = get_dataset(val_df, n_shards=16)\n",
    "ds_val = ds_val.batch(P[\"BATCH_SIZE\"]).cache()\n",
    "ds_val = ds_val.map(lambda x, y: (tf.image.convert_image_dtype(x, tf.float32), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82211657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "{0: 3.75, 1: 3.5294117647058822, 2: 3.5294117647058822, 3: 2.608695652173913, 4: 3.75, 5: 2.608695652173913, 6: 2.5, 7: 2.5, 8: 2.2222222222222223, 9: 2.2222222222222223, 10: 1.6666666666666667, 11: 1.6216216216216217, 12: 1.5, 13: 1.4634146341463414, 14: 0.8823529411764706, 15: 0.7228915662650602, 16: 0.5555555555555556, 17: 0.36363636363636365, 18: 0.3314917127071823, 19: 0.2643171806167401}\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_df[\"class\"].unique())\n",
    "print(num_classes)\n",
    "\n",
    "class_weight = compute_class_weight(\"balanced\", classes=np.arange(num_classes), y=train_df[\"class\"])\n",
    "class_weight = dict({i:class_weight[i] for i in range(len(class_weight))})\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d863caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(224, 224, 3)),\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\",trainable=False),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "831c1547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 2048)              23564800  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                40980     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,605,780\n",
      "Trainable params: 40,980\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688924ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8758de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d1e8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44c68c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d73a5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c04099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ebd7175",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "38/38 [==============================] - 12s 155ms/step - loss: 2.4611 - accuracy: 0.3242 - val_loss: 1.5135 - val_accuracy: 0.5367\n",
      "Epoch 2/25\n",
      "38/38 [==============================] - 2s 64ms/step - loss: 1.3844 - accuracy: 0.6583 - val_loss: 1.2433 - val_accuracy: 0.6333\n",
      "Epoch 3/25\n",
      "38/38 [==============================] - 2s 63ms/step - loss: 1.0365 - accuracy: 0.7492 - val_loss: 1.1148 - val_accuracy: 0.6600\n",
      "Epoch 4/25\n",
      "38/38 [==============================] - 2s 63ms/step - loss: 0.8235 - accuracy: 0.8067 - val_loss: 1.0354 - val_accuracy: 0.6867\n",
      "Epoch 5/25\n",
      "38/38 [==============================] - 2s 63ms/step - loss: 0.6776 - accuracy: 0.8475 - val_loss: 0.9805 - val_accuracy: 0.7100\n",
      "Epoch 6/25\n",
      "38/38 [==============================] - 2s 63ms/step - loss: 0.5710 - accuracy: 0.8800 - val_loss: 0.9399 - val_accuracy: 0.7300\n",
      "Epoch 7/25\n",
      "38/38 [==============================] - 2s 63ms/step - loss: 0.4893 - accuracy: 0.8958 - val_loss: 0.9074 - val_accuracy: 0.7300\n",
      "Epoch 8/25\n",
      "38/38 [==============================] - 2s 65ms/step - loss: 0.4240 - accuracy: 0.9083 - val_loss: 0.8805 - val_accuracy: 0.7567\n",
      "Epoch 9/25\n",
      "38/38 [==============================] - 2s 64ms/step - loss: 0.3709 - accuracy: 0.9208 - val_loss: 0.8583 - val_accuracy: 0.7633\n",
      "Epoch 10/25\n",
      "38/38 [==============================] - 2s 64ms/step - loss: 0.3272 - accuracy: 0.9367 - val_loss: 0.8404 - val_accuracy: 0.7767\n",
      "Epoch 11/25\n",
      "38/38 [==============================] - 2s 65ms/step - loss: 0.2908 - accuracy: 0.9458 - val_loss: 0.8263 - val_accuracy: 0.7733\n",
      "Epoch 12/25\n",
      "38/38 [==============================] - 2s 64ms/step - loss: 0.2603 - accuracy: 0.9542 - val_loss: 0.8152 - val_accuracy: 0.7733\n",
      "Epoch 13/25\n",
      "38/38 [==============================] - 2s 63ms/step - loss: 0.2344 - accuracy: 0.9592 - val_loss: 0.8067 - val_accuracy: 0.7767\n",
      "Epoch 14/25\n",
      "38/38 [==============================] - 2s 66ms/step - loss: 0.2122 - accuracy: 0.9633 - val_loss: 0.8004 - val_accuracy: 0.7800\n",
      "Epoch 15/25\n",
      "38/38 [==============================] - 3s 66ms/step - loss: 0.1930 - accuracy: 0.9683 - val_loss: 0.7957 - val_accuracy: 0.7800\n",
      "Epoch 16/25\n",
      "38/38 [==============================] - 2s 64ms/step - loss: 0.1763 - accuracy: 0.9708 - val_loss: 0.7924 - val_accuracy: 0.7867\n",
      "Epoch 17/25\n",
      "38/38 [==============================] - 2s 64ms/step - loss: 0.1617 - accuracy: 0.9725 - val_loss: 0.7901 - val_accuracy: 0.7867\n",
      "Epoch 18/25\n",
      "38/38 [==============================] - 2s 62ms/step - loss: 0.1489 - accuracy: 0.9750 - val_loss: 0.7888 - val_accuracy: 0.7867\n",
      "Epoch 19/25\n",
      "38/38 [==============================] - 2s 64ms/step - loss: 0.1375 - accuracy: 0.9758 - val_loss: 0.7881 - val_accuracy: 0.7800\n",
      "Epoch 20/25\n",
      "38/38 [==============================] - 2s 64ms/step - loss: 0.1274 - accuracy: 0.9800 - val_loss: 0.7880 - val_accuracy: 0.7800\n",
      "Epoch 21/25\n",
      "38/38 [==============================] - 2s 64ms/step - loss: 0.1184 - accuracy: 0.9825 - val_loss: 0.7884 - val_accuracy: 0.7767\n",
      "Epoch 22/25\n",
      "38/38 [==============================] - 2s 64ms/step - loss: 0.1103 - accuracy: 0.9825 - val_loss: 0.7892 - val_accuracy: 0.7833\n",
      "Epoch 23/25\n",
      "38/38 [==============================] - 2s 64ms/step - loss: 0.1030 - accuracy: 0.9833 - val_loss: 0.7903 - val_accuracy: 0.7833\n",
      "Epoch 24/25\n",
      "38/38 [==============================] - 2s 63ms/step - loss: 0.0964 - accuracy: 0.9842 - val_loss: 0.7916 - val_accuracy: 0.7833\n",
      "Epoch 25/25\n",
      "38/38 [==============================] - 2s 63ms/step - loss: 0.0905 - accuracy: 0.9867 - val_loss: 0.7931 - val_accuracy: 0.7833\n",
      "Epoch 1/25\n",
      "38/38 [==============================] - 15s 208ms/step - loss: 1.5319 - accuracy: 0.6767 - val_loss: 1.4831 - val_accuracy: 0.6867\n",
      "Epoch 2/25\n",
      "38/38 [==============================] - 6s 171ms/step - loss: 0.3556 - accuracy: 0.9575 - val_loss: 1.2126 - val_accuracy: 0.7233\n",
      "Epoch 3/25\n",
      "38/38 [==============================] - 6s 169ms/step - loss: 0.2730 - accuracy: 0.9983 - val_loss: 1.1692 - val_accuracy: 0.7433\n",
      "Epoch 4/25\n",
      "38/38 [==============================] - 6s 168ms/step - loss: 0.2636 - accuracy: 1.0000 - val_loss: 1.1771 - val_accuracy: 0.7733\n",
      "Epoch 5/25\n",
      "38/38 [==============================] - 6s 168ms/step - loss: 0.2605 - accuracy: 1.0000 - val_loss: 1.1923 - val_accuracy: 0.7600\n",
      "Epoch 6/25\n",
      "38/38 [==============================] - 6s 170ms/step - loss: 0.2589 - accuracy: 1.0000 - val_loss: 1.2035 - val_accuracy: 0.7700\n",
      "Epoch 7/25\n",
      "38/38 [==============================] - 7s 185ms/step - loss: 0.2579 - accuracy: 1.0000 - val_loss: 1.2117 - val_accuracy: 0.7667\n",
      "Epoch 8/25\n",
      "38/38 [==============================] - 7s 174ms/step - loss: 0.2572 - accuracy: 1.0000 - val_loss: 1.2196 - val_accuracy: 0.7600\n",
      "Epoch 9/25\n",
      "38/38 [==============================] - 6s 170ms/step - loss: 0.2567 - accuracy: 1.0000 - val_loss: 1.2268 - val_accuracy: 0.7567\n",
      "Epoch 10/25\n",
      "38/38 [==============================] - 7s 172ms/step - loss: 0.2563 - accuracy: 1.0000 - val_loss: 1.2325 - val_accuracy: 0.7533\n",
      "Epoch 11/25\n",
      "38/38 [==============================] - 7s 172ms/step - loss: 0.2560 - accuracy: 1.0000 - val_loss: 1.2378 - val_accuracy: 0.7533\n",
      "Epoch 12/25\n",
      "38/38 [==============================] - 6s 169ms/step - loss: 0.2557 - accuracy: 1.0000 - val_loss: 1.2416 - val_accuracy: 0.7533\n",
      "Epoch 13/25\n",
      "38/38 [==============================] - 6s 170ms/step - loss: 0.2554 - accuracy: 1.0000 - val_loss: 1.2453 - val_accuracy: 0.7533\n",
      "Epoch 14/25\n",
      "38/38 [==============================] - 6s 167ms/step - loss: 0.2552 - accuracy: 1.0000 - val_loss: 1.2487 - val_accuracy: 0.7533\n",
      "Epoch 15/25\n",
      "38/38 [==============================] - 6s 167ms/step - loss: 0.2551 - accuracy: 1.0000 - val_loss: 1.2525 - val_accuracy: 0.7533\n",
      "Epoch 16/25\n",
      "38/38 [==============================] - 6s 171ms/step - loss: 0.2549 - accuracy: 1.0000 - val_loss: 1.2550 - val_accuracy: 0.7567\n",
      "Epoch 17/25\n",
      "38/38 [==============================] - 7s 188ms/step - loss: 0.2547 - accuracy: 1.0000 - val_loss: 1.2579 - val_accuracy: 0.7533\n",
      "Epoch 18/25\n",
      "38/38 [==============================] - 7s 187ms/step - loss: 0.2546 - accuracy: 1.0000 - val_loss: 1.2603 - val_accuracy: 0.7533\n",
      "Epoch 19/25\n",
      "38/38 [==============================] - 7s 186ms/step - loss: 0.2544 - accuracy: 1.0000 - val_loss: 1.2627 - val_accuracy: 0.7567\n",
      "Epoch 20/25\n",
      "38/38 [==============================] - 7s 178ms/step - loss: 0.2543 - accuracy: 1.0000 - val_loss: 1.2648 - val_accuracy: 0.7567\n",
      "Epoch 21/25\n",
      "38/38 [==============================] - 7s 173ms/step - loss: 0.2542 - accuracy: 1.0000 - val_loss: 1.2667 - val_accuracy: 0.7567\n",
      "Epoch 22/25\n",
      "38/38 [==============================] - 7s 178ms/step - loss: 0.2541 - accuracy: 1.0000 - val_loss: 1.2684 - val_accuracy: 0.7567\n",
      "Epoch 23/25\n",
      "38/38 [==============================] - 7s 181ms/step - loss: 0.2539 - accuracy: 1.0000 - val_loss: 1.2704 - val_accuracy: 0.7567\n",
      "Epoch 24/25\n",
      "38/38 [==============================] - 7s 179ms/step - loss: 0.2538 - accuracy: 1.0000 - val_loss: 1.2723 - val_accuracy: 0.7567\n",
      "Epoch 25/25\n",
      "38/38 [==============================] - 7s 182ms/step - loss: 0.2537 - accuracy: 1.0000 - val_loss: 1.2740 - val_accuracy: 0.7567\n"
     ]
    }
   ],
   "source": [
    "exp_name = \"classification\"\n",
    "experiment = mlflow.get_experiment_by_name(exp_name)\n",
    "if experiment is not None:\n",
    "    mlflow.delete_experiment(experiment.experiment_id)\n",
    "    hp.config.clean_mlflow_trash()\n",
    "\n",
    "exp_id = mlflow.create_experiment(name=exp_name)    \n",
    "        \n",
    "\n",
    "with mlflow.start_run(experiment_id=exp_id) as run:\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=P[\"LEARNING_RATE\"]),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(ds_train,\n",
    "                        validation_data=ds_val,\n",
    "                        epochs=P[\"EPOCHS\"], \n",
    "                        steps_per_epoch=P[\"STEPS_PER_EPOCH\"],\n",
    "                        class_weight=class_weight)\n",
    "    \n",
    "    mlflow.log_dict(history.history, \"history.json\")\n",
    "    \n",
    "    # Allow finetuning\n",
    "    for l in model.layers:\n",
    "        l.trainable = True\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=P[\"LEARNING_RATE_FINETUNING\"]),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(ds_train,\n",
    "                        validation_data=ds_val,\n",
    "                        epochs=P[\"EPOCHS\"], \n",
    "                        steps_per_epoch=P[\"STEPS_PER_EPOCH\"],\n",
    "                        class_weight=class_weight)\n",
    "                                                                     \n",
    "    mlflow.log_dict(history.history, \"history-finetune.json\")\n",
    "    \n",
    "    mlflow.log_dict(P, \"params.yaml\")\n",
    "                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "474855c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>status</th>\n",
       "      <th>artifact_uri</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>tags.mlflow.source.type</th>\n",
       "      <th>tags.mlflow.user</th>\n",
       "      <th>tags.mlflow.source.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18c0acfb9ab944dbaa1adf9e17e9cc51</td>\n",
       "      <td>1</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>file:///home/salemi/Documents/Kaggle/happywhal...</td>\n",
       "      <td>2022-02-06 00:03:52.611000+00:00</td>\n",
       "      <td>2022-02-06 00:07:56.358000+00:00</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>salemi</td>\n",
       "      <td>/home/salemi/miniconda3/envs/happywhale/lib/py...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id experiment_id    status  \\\n",
       "0  18c0acfb9ab944dbaa1adf9e17e9cc51             1  FINISHED   \n",
       "\n",
       "                                        artifact_uri  \\\n",
       "0  file:///home/salemi/Documents/Kaggle/happywhal...   \n",
       "\n",
       "                        start_time                         end_time  \\\n",
       "0 2022-02-06 00:03:52.611000+00:00 2022-02-06 00:07:56.358000+00:00   \n",
       "\n",
       "  tags.mlflow.source.type tags.mlflow.user  \\\n",
       "0                   LOCAL           salemi   \n",
       "\n",
       "                             tags.mlflow.source.name  \n",
       "0  /home/salemi/miniconda3/envs/happywhale/lib/py...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = mlflow.search_runs(exp_id)\n",
    "\n",
    "runs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92c7778d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///home/salemi/Documents/Kaggle/happywhale/mlflow/1/18c0acfb9ab944dbaa1adf9e17e9cc51/artifacts'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs.at[0, \"artifact_uri\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
