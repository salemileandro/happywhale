{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e78b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py as h5\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Custom library in dev\n",
    "import happy as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c00b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = {}\n",
    "\n",
    "P[\"TRAIN_CSV\"] = \"input/happy-whale-and-dolphin/train.csv\"\n",
    "\n",
    "P[\"TRAIN_FOLDER\"] = \"input/happy-whale-and-dolphin/train_images\"\n",
    "\n",
    "P[\"BATCH_SIZE\"] = 32\n",
    "\n",
    "P[\"EPOCHS\"] = 3\n",
    "\n",
    "P[\"LEARNING_RATE\"] = 1e-3\n",
    "\n",
    "P[\"LEARNING_RATE_FINETUNING\"] = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "537a84eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(P[\"TRAIN_CSV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f3e649f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS NAME                    COUNTS    PERCENTAGE\n",
      "--------------------------------------------------\n",
      "bottlenose_dolphin            9664      18.94     \n",
      "beluga                        7443      14.58     \n",
      "humpback_whale                7392      14.48     \n",
      "blue_whale                    4830      9.46      \n",
      "false_killer_whale            3326      6.52      \n",
      "dusky_dolphin                 3139      6.15      \n",
      "spinner_dolphin               1700      3.33      \n",
      "melon_headed_whale            1689      3.31      \n",
      "minke_whale                   1608      3.15      \n",
      "killer_whale                  1493      2.93      \n",
      "fin_whale                     1324      2.59      \n",
      "gray_whale                    1123      2.20      \n",
      "bottlenose_dolpin             1117      2.19      \n",
      "kiler_whale                   962       1.89      \n",
      "southern_right_whale          866       1.70      \n",
      "spotted_dolphin               490       0.96      \n",
      "sei_whale                     428       0.84      \n",
      "short_finned_pilot_whale      367       0.72      \n",
      "common_dolphin                347       0.68      \n",
      "cuviers_beaked_whale          341       0.67      \n",
      "pilot_whale                   262       0.51      \n",
      "long_finned_pilot_whale       238       0.47      \n",
      "white_sided_dolphin           229       0.45      \n",
      "brydes_whale                  154       0.30      \n",
      "pantropic_spotted_dolphin     145       0.28      \n",
      "globis                        116       0.23      \n",
      "commersons_dolphin            90        0.18      \n",
      "pygmy_killer_whale            76        0.15      \n",
      "rough_toothed_dolphin         60        0.12      \n",
      "frasiers_dolphin              14        0.03      \n"
     ]
    }
   ],
   "source": [
    "hp.print_class_statistics(data_df, \"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c12e2f",
   "metadata": {},
   "source": [
    "The classes in this dataset, the column \"species\", are too imbalanced. Let's group some less represented classes to get something significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6b002b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>species</th>\n",
       "      <th>individual_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00021adfb725ed.jpg</td>\n",
       "      <td>melon_headed_whale</td>\n",
       "      <td>cadddb1636b9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000562241d384d.jpg</td>\n",
       "      <td>humpback_whale</td>\n",
       "      <td>1a71fbb72250</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0007c33415ce37.jpg</td>\n",
       "      <td>false_killer_whale</td>\n",
       "      <td>60008f293a2b</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0007d9bca26a99.jpg</td>\n",
       "      <td>bottlenose_dolphin</td>\n",
       "      <td>4b00fe572063</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00087baf5cef7a.jpg</td>\n",
       "      <td>humpback_whale</td>\n",
       "      <td>8e5253662392</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                image             species individual_id  class\n",
       "0  00021adfb725ed.jpg  melon_headed_whale  cadddb1636b9     10\n",
       "1  000562241d384d.jpg      humpback_whale  1a71fbb72250     15\n",
       "2  0007c33415ce37.jpg  false_killer_whale  60008f293a2b     13\n",
       "3  0007d9bca26a99.jpg  bottlenose_dolphin  4b00fe572063     17\n",
       "4  00087baf5cef7a.jpg      humpback_whale  8e5253662392     15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classes are too much imbalanced, let's group the one with few example\n",
    "\n",
    "cutoff = 800 # Minimum number of sample for a species to be considered\n",
    "\n",
    "\n",
    "unique_species, count_species = np.unique(data_df[\"species\"], return_counts=True)\n",
    "\n",
    "unique_species = unique_species[np.argsort(count_species)]\n",
    "count_species = count_species[np.argsort(count_species)]\n",
    "\n",
    "map_species = {}\n",
    "idx = 0 \n",
    "acc = 0\n",
    "name = []\n",
    "for i, j in zip(count_species, unique_species):\n",
    "    acc += i\n",
    "    name.append(j)    \n",
    "    if acc >= cutoff:\n",
    "        for n in name:\n",
    "            map_species[n] = idx\n",
    "        idx += 1\n",
    "        acc = 0\n",
    "        name = []\n",
    "            \n",
    "        \n",
    "    \n",
    "data_df[\"class\"] = data_df.apply(lambda x: map_species[x[\"species\"]], axis=1)\n",
    "        \n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c163c6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS NAME                    COUNTS    PERCENTAGE\n",
      "--------------------------------------------------\n",
      "17                            9664      18.94     \n",
      "16                            7443      14.58     \n",
      "15                            7392      14.48     \n",
      "14                            4830      9.46      \n",
      "13                            3326      6.52      \n",
      "12                            3139      6.15      \n",
      "11                            1700      3.33      \n",
      "10                            1689      3.31      \n",
      "9                             1608      3.15      \n",
      "8                             1493      2.93      \n",
      "3                             1356      2.66      \n",
      "7                             1324      2.59      \n",
      "2                             1142      2.24      \n",
      "6                             1123      2.20      \n",
      "5                             1117      2.19      \n",
      "4                             962       1.89      \n",
      "0                             884       1.73      \n",
      "1                             841       1.65      \n"
     ]
    }
   ],
   "source": [
    "hp.print_class_statistics(data_df, \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df40eec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for train set:\n",
      "CLASS NAME                    COUNTS    PERCENTAGE\n",
      "--------------------------------------------------\n",
      "17                            7731      18.94     \n",
      "16                            5955      14.59     \n",
      "15                            5913      14.48     \n",
      "14                            3864      9.46      \n",
      "13                            2661      6.52      \n",
      "12                            2511      6.15      \n",
      "11                            1360      3.33      \n",
      "10                            1351      3.31      \n",
      "9                             1286      3.15      \n",
      "8                             1194      2.92      \n",
      "3                             1085      2.66      \n",
      "7                             1059      2.59      \n",
      "2                             913       2.24      \n",
      "6                             899       2.20      \n",
      "5                             894       2.19      \n",
      "4                             770       1.89      \n",
      "0                             707       1.73      \n",
      "1                             673       1.65      \n",
      "\n",
      "Stats for val set:\n",
      "CLASS NAME                    COUNTS    PERCENTAGE\n",
      "--------------------------------------------------\n",
      "17                            1933      18.94     \n",
      "16                            1488      14.58     \n",
      "15                            1479      14.49     \n",
      "14                            966       9.46      \n",
      "13                            665       6.52      \n",
      "12                            628       6.15      \n",
      "11                            340       3.33      \n",
      "10                            338       3.31      \n",
      "9                             322       3.15      \n",
      "8                             299       2.93      \n",
      "3                             271       2.66      \n",
      "7                             265       2.60      \n",
      "2                             229       2.24      \n",
      "6                             224       2.19      \n",
      "5                             223       2.18      \n",
      "4                             192       1.88      \n",
      "0                             177       1.73      \n",
      "1                             168       1.65      \n"
     ]
    }
   ],
   "source": [
    "# 80 / 20 split\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "train_index, val_index = next(skf.split(np.zeros(len(data_df)), data_df[\"class\"].values))\n",
    "\n",
    "train_df = data_df.loc[train_index].copy()\n",
    "val_df = data_df.loc[val_index].copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Stats for train set:\")\n",
    "hp.print_class_statistics(train_df, \"class\")\n",
    "\n",
    "print(\"\\nStats for val set:\")\n",
    "hp.print_class_statistics(val_df, \"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780189d9",
   "metadata": {},
   "source": [
    "The splits looks fairly good with a conserved class prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "354d3dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 76 122 171]\n",
      "  [ 76 124 170]\n",
      "  [ 84 127 174]\n",
      "  ...\n",
      "  [ 62 100 147]\n",
      "  [ 63  99 151]\n",
      "  [ 60 101 150]]\n",
      "\n",
      " [[ 89 136 178]\n",
      "  [ 86 134 174]\n",
      "  [ 94 139 179]\n",
      "  ...\n",
      "  [ 49  86 131]\n",
      "  [ 53  87 136]\n",
      "  [ 56  90 138]]\n",
      "\n",
      " [[ 87 132 174]\n",
      "  [ 92 137 178]\n",
      "  [ 90 136 177]\n",
      "  ...\n",
      "  [ 58  92 137]\n",
      "  [ 59  93 138]\n",
      "  [ 60  92 139]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 47  44  53]\n",
      "  [ 47  46  54]\n",
      "  [ 44  44  52]\n",
      "  ...\n",
      "  [ 48  47  55]\n",
      "  [ 47  47  55]\n",
      "  [ 49  46  55]]\n",
      "\n",
      " [[ 43  43  51]\n",
      "  [ 42  42  50]\n",
      "  [ 47  46  54]\n",
      "  ...\n",
      "  [ 49  48  56]\n",
      "  [ 48  48  56]\n",
      "  [ 48  47  55]]\n",
      "\n",
      " [[ 40  43  52]\n",
      "  [ 43  43  53]\n",
      "  [ 43  41  52]\n",
      "  ...\n",
      "  [ 51  50  59]\n",
      "  [ 52  51  59]\n",
      "  [ 49  49  57]]], shape=(224, 224, 3), dtype=uint8) tf.Tensor(10, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "class ShardedGenerator:\n",
    "    def __init__(self, df: pd.DataFrame, n_shards: int = None):\n",
    "        \n",
    "        self._df = df.copy()\n",
    "                \n",
    "        self._n_shards = n_shards\n",
    "        if self._n_shards is None:\n",
    "            self._n_shards = cpu_count()\n",
    "            \n",
    "        self._df[\"filepath\"] = self._df.apply(lambda x: os.path.join(P[\"TRAIN_FOLDER\"], x[\"image\"]), axis=1)\n",
    "        \n",
    "        \n",
    "    def __call__(self, n):\n",
    "        with h5.File(\"preprocessed_224-224/data.h5\", \"r\") as f:\n",
    "            for count, (i, row) in enumerate(self._df.iterrows()):\n",
    "                if count % self._n_shards != n:\n",
    "                    continue\n",
    "                    \n",
    "                img = tf.convert_to_tensor(f[\"img\"][i])\n",
    "                \n",
    "                label = tf.convert_to_tensor(row[\"class\"], dtype=tf.int64)\n",
    "\n",
    "                yield img, label\n",
    "                \n",
    "                \n",
    "gen = ShardedGenerator(train_df, 1)\n",
    "\n",
    "for i, j in gen(0):\n",
    "    print(i, j)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "423d74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(data:pd.DataFrame, n_shards=4):\n",
    "    gen = ShardedGenerator(data, n_shards)\n",
    "\n",
    "    out_sign = (tf.TensorSpec(shape=(224, 224, 3), dtype=tf.uint8), tf.TensorSpec(shape=(), dtype=tf.int64))\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices(np.arange(n_shards))\n",
    "\n",
    "    ds = ds.interleave(lambda x: tf.data.Dataset.from_generator(gen, output_signature=out_sign, args=(x,)),\n",
    "                       cycle_length=n_shards,\n",
    "                       block_length=1,\n",
    "                       num_parallel_calls=n_shards,\n",
    "                       deterministic=True)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "\n",
    "STEPS_PER_EPOCH = np.ceil(len(train_df) / P[\"BATCH_SIZE\"])\n",
    "\n",
    "\n",
    "ds_train = get_dataset(train_df, n_shards=16)\n",
    "ds_train = ds_train.batch(P[\"BATCH_SIZE\"]).cache()\n",
    "ds_train = ds_train.map(lambda x, y: (tf.image.convert_image_dtype(x, tf.float32), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE).repeat(P[\"EPOCHS\"])\n",
    "\n",
    "\n",
    "ds_val = get_dataset(val_df, n_shards=16)\n",
    "ds_val = ds_val.batch(P[\"BATCH_SIZE\"]).cache()\n",
    "ds_val = ds_val.map(lambda x, y: (tf.image.convert_image_dtype(x, tf.float32), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01d26011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "{0: 3.208077950652208, 1: 3.3701502393924385, 2: 2.484239990264087, 3: 2.0904249871991807, 4: 2.9455988455988455, 5: 2.537037037037037, 6: 2.5229267086886664, 7: 2.1417479802748924, 8: 1.8995905453191886, 9: 1.763694487644721, 10: 1.6788387202894974, 11: 1.6677287581699347, 12: 0.9032700561971768, 13: 0.8523529166144724, 14: 0.5869852772026685, 15: 0.38358043482345866, 16: 0.3808750816307491, 17: 0.29337874933528796}\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_df[\"class\"].unique())\n",
    "print(num_classes)\n",
    "\n",
    "class_weight = compute_class_weight(\"balanced\", classes=np.arange(num_classes), y=train_df[\"class\"])\n",
    "class_weight = dict({i:class_weight[i] for i in range(len(class_weight))})\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "829913de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(224, 224, 3)),\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\",trainable=False),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a3cef26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 2048)              23564800  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 18)                36882     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,601,682\n",
      "Trainable params: 36,882\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59729d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1276/1276 [==============================] - 207s 158ms/step - loss: 0.9660 - accuracy: 0.7501 - val_loss: 0.6263 - val_accuracy: 0.8057\n",
      "Epoch 2/3\n",
      "1276/1276 [==============================] - 84s 66ms/step - loss: 0.6100 - accuracy: 0.8331 - val_loss: 0.5549 - val_accuracy: 0.8267\n",
      "Epoch 3/3\n",
      "1276/1276 [==============================] - 84s 66ms/step - loss: 0.5023 - accuracy: 0.8568 - val_loss: 0.5155 - val_accuracy: 0.8382\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(ds_train, validation_data=ds_val, epochs=P[\"EPOCHS\"], \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54cdcc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=P[\"LEARNING_RATE_FINETUNING\"]),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f3e4f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in model.layers:\n",
    "    l.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ac60857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 2048)              23564800  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 18)                36882     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,601,682\n",
      "Trainable params: 23,556,242\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fddd41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1276/1276 [==============================] - 85s 65ms/step - loss: 0.3971 - accuracy: 0.8851 - val_loss: 0.4700 - val_accuracy: 0.8562\n",
      "Epoch 2/3\n",
      "1276/1276 [==============================] - 84s 66ms/step - loss: 0.3894 - accuracy: 0.8893 - val_loss: 0.4674 - val_accuracy: 0.8567\n",
      "Epoch 3/3\n",
      "1276/1276 [==============================] - 82s 64ms/step - loss: 0.3864 - accuracy: 0.8900 - val_loss: 0.4656 - val_accuracy: 0.8569\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(ds_train, validation_data=ds_val, epochs=P[\"EPOCHS\"],\n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2569452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.3970639705657959, 0.38937488198280334, 0.3863593637943268],\n",
       " 'accuracy': [0.8851222395896912, 0.8892862200737, 0.8899720907211304],\n",
       " 'val_loss': [0.46997886896133423, 0.46740734577178955, 0.46557819843292236],\n",
       " 'val_accuracy': [0.8561771512031555, 0.8566669821739197, 0.8568629622459412]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c437d654",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 tf.Tensor([15], shape=(1,), dtype=int64)\n",
      "4 tf.Tensor([7], shape=(1,), dtype=int64)\n",
      "15 tf.Tensor([15], shape=(1,), dtype=int64)\n",
      "9 tf.Tensor([9], shape=(1,), dtype=int64)\n",
      "16 tf.Tensor([16], shape=(1,), dtype=int64)\n",
      "8 tf.Tensor([8], shape=(1,), dtype=int64)\n",
      "9 tf.Tensor([9], shape=(1,), dtype=int64)\n",
      "13 tf.Tensor([13], shape=(1,), dtype=int64)\n",
      "8 tf.Tensor([2], shape=(1,), dtype=int64)\n",
      "2 tf.Tensor([2], shape=(1,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for i, j in ds_val.unbatch().take(10).batch(1):\n",
    "    y = model.predict(i)\n",
    "    print(np.argmax(y), j)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
